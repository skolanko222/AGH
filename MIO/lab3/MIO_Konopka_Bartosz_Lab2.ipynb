{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmJQ3Skr7fcq"
      },
      "source": [
        "# Konopka Bartosz - grupa 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msysGYfP9MiD"
      },
      "source": [
        "# Wstęp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzZP_q3yrlSk"
      },
      "source": [
        "W poniższych zadaniach wykorzystaliśmy i badaliśmy sieci wielowarstwowe, korzystając z modelu MLPClassifier. Korzystając z odpowiednich zbiorów danych przetestowaliśmy zależności takie jak struktura sieci, skuteczność sieci w wielu problemach oraz wpływ różnych architektur sieci, funkcji aktywacji, ilości epok uczenia i algorytmów uczenia na wynik zadania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmvuBHoM9cUq"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "from sklearn import preprocessing\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN9Af1iL9TEz"
      },
      "source": [
        "# ZAD 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfcUlgi_9vKO"
      },
      "source": [
        "## Kod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u6_HFvg97En"
      },
      "source": [
        "Treść:\n",
        "\n",
        "Proszę pobrać plik medicine.txt, zawierający wyniki analizy nowego leku. W dwóch pierwszych kolumnach znajduje się stężenie dwóch składników w próbce krwi, w trzeciej - informacja o tym, czy lek zadziałał. Dane nie są znormalizowane. Proszę znormalizować dane, podzielić je na zbiór uczący i testujący w proporcjach 80-20 (należy pamiętać o proporcjach klas), zaproponować wielowarstwową sieć neuronową i zbadać jej skuteczność dla różnych ilości warstw i neuronów w tych warstwach. Proszę narysować w jaki sposób sieć dokonała podziału w zbiorze dla kilku sieci (zarówno tych z dobrymi, jak i złymi wynikami) oraz jak wygląda poprawny podział zbioru. Proszę również przedstawić wyniki dla 5-8 różnych struktur sieci, wraz z oceną, która z nich najlepiej poradziła sobie z zadaniem klasyfikacji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-39h66m9Uep"
      },
      "outputs": [],
      "source": [
        "data_medicine = pd.read_csv('medicine.txt', sep = ',', header = None)\n",
        "data_medicine = data_medicine.drop(0)\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "X = scaler.fit_transform(data_medicine.iloc[:,0:2])\n",
        "Y = data_medicine.iloc[:,2]\n",
        "Y = Y.to_numpy()\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dX2GlQu6JADD",
        "outputId": "8730c098-1615-49a3-8678-7e95c43afa24"
      },
      "outputs": [],
      "source": [
        "layers = [(1,1), (5,5), (10,5), (10,10), (50,20), (10,5,2), (50,20,5), (100,50,20)]\n",
        "\n",
        "for i in layers:\n",
        "  model = MLPClassifier(hidden_layer_sizes = i, max_iter=2000)\n",
        "  model.fit(X_train, Y_train)\n",
        "  display = DecisionBoundaryDisplay.from_estimator(model, X_train, cmap='viridis')\n",
        "  plt.scatter(X_train[:,0],X_train[:,1], c=Y_train)\n",
        "\n",
        "  predicted_labels = model.predict(X_test)\n",
        "  print(\"score: \", model.score(X_train,Y_train))\n",
        "\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZZvBhr89wxI"
      },
      "source": [
        "## Wnioski"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j8OgqK54mvV"
      },
      "source": [
        "W eksperymencie z klasyfikacją nowego leku za pomocą wielowarstwowej sieci neuronowej, różne konfiguracje sieci przynosiły zróżnicowane wyniki skuteczności. W przypadku prostszych struktur, składających się z jednej lub dwóch warstw o mniejszej liczbie neuronów, skuteczność była niższa. Jednak złożone modele z większą liczbą warstw i neuronów wykazywały tendencję do poprawy skuteczności. W niektórych przypadkach zwiększenie złożoności sieci nie przynosiło istotnej poprawy wyników. Najlepsze rezultaty uzyskano przy modelu z trzema warstwami (100, 50, 20), osiągając accuracy na poziomie 0.915."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkKkoZKL9VIK"
      },
      "source": [
        "# ZAD 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCSJq63WMkDi"
      },
      "source": [
        "## Kod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQiyDyrNMnEG"
      },
      "source": [
        "Treść:\n",
        "\n",
        "Proszę pobrać zbiór ręcznie pisanych cyfr z https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits (można to zrobić funkcją datasets.load_digits() w sklearnie). Proszę sprawdzić skuteczność klasyfikacji na tym zbiorze za pomocą wielowarstwowej sieci neuronowej."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x05ldzhO9Xfy"
      },
      "outputs": [],
      "source": [
        "data_digits = datasets.load_digits()\n",
        "\n",
        "X = data_digits.data\n",
        "Y = data_digits.target\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOHgNmo7OY5c",
        "outputId": "739fad5f-23e9-4c08-93c4-0974d68ff7d8"
      },
      "outputs": [],
      "source": [
        "model = MLPClassifier(solver = \"sgd\", hidden_layer_sizes=(100,50), max_iter = 1000, tol = 0.001, activation = 'identity')\n",
        "\n",
        "model.fit(X_train,Y_train)\n",
        "predicted_labels = model.predict(X_train)\n",
        "\n",
        "print(confusion_matrix(Y_train, predicted_labels))\n",
        "print(model.score(X_test,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yrCK8eYMlmO"
      },
      "source": [
        "## Wnioski"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ArqiP3f5Kfr"
      },
      "source": [
        "Skuteczność klasyfikacji na zbiorze ręcznie pisanych cyfr za pomocą wielowarstwowej sieci neuronowej wynosiła 0.9638888888888889 na zbiorze testowym. Jest to bardzo wysoki wynik, co sugeruje, że model dobrze radzi sobie z zadaniem rozpoznawania cyfr na podstawie obrazów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGiGkjR89YNU"
      },
      "source": [
        "# ZAD 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uWn-ORuOug4"
      },
      "source": [
        "## Kod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2ZlB4xcOxC8"
      },
      "source": [
        "Treść:\n",
        "\n",
        "Proszę sprawdzić, jak zmieni się poprawność klasyfikacji na zbiorze ręcznie pisanych cyfr dla różnych architektur sieci, funkcji aktywacji, ilości epok uczenia i algorytmów uczenia. Proszę zbadać wpływ współczynnika uczenia (learning_rate) podczas używania algorytmu SGD. Dla najciekawszych przykładów proszę wypisać macierze pomyłek."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBc-KS-S9ZXf"
      },
      "outputs": [],
      "source": [
        "data_digits = datasets.load_digits()\n",
        "\n",
        "X = data_digits.data\n",
        "Y = data_digits.target\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz_tqidcasI3",
        "outputId": "f493716a-1814-41a0-fad3-eeff5f3e735b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number: 79, Architecture: (10, 5, 5, 5, 5, 5), Activation: tanh, Epochs: 2000, Learning Rate: 0.01, Optimizer: sgd\n",
            "Test Accuracy: 0.7638888888888888\n",
            "\n",
            "Number: 80, Architecture: (10, 5, 5, 5, 5, 5), Activation: tanh, Epochs: 2000, Learning Rate: 0.001, Optimizer: sgd\n",
            "Test Accuracy: 0.6527777777777778\n",
            "Confusion Matrix:\n",
            "[[34  0  1  0  0  1  0  0  0  0]\n",
            " [ 0 29  4  2  1  0  0  0  0  0]\n",
            " [ 0  6 29  0  0  0  0  0  0  0]\n",
            " [ 2  0  0 33  1  0  0  0  1  0]\n",
            " [ 0  0  0  1  7  0 26  0  2  0]\n",
            " [ 5  1  3  3  0 25  0  0  0  0]\n",
            " [ 1  0  0  0  2  0 32  1  0  0]\n",
            " [ 0  0  0  2  0  1  2 31  0  0]\n",
            " [ 0 15  0 10  0  0  1  0  9  0]\n",
            " [14  1  1  4  0  4  0  0  6  6]]\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/skolanko/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        }
      ],
      "source": [
        "architectures = [(10, 5,5,5), (10, 5,5,5,5), (10, 5,5,5,5,5)]\n",
        "activation_functions = ['relu', 'logistic', 'tanh']\n",
        "epochs = [500, 1000, 2000]\n",
        "learning_rates = [0.1, 0.01, 0.001]\n",
        "optimizers = ['sgd']\n",
        "i = 0\n",
        "\n",
        "for architecture in architectures:\n",
        "    for activation_function in activation_functions:\n",
        "        for epoch in epochs:\n",
        "            for learning_rate in learning_rates:\n",
        "                for optimizer in optimizers:\n",
        "                    model = MLPClassifier(hidden_layer_sizes=architecture, activation=activation_function, max_iter=epoch, learning_rate_init=learning_rate, solver=optimizer)\n",
        "                    model.fit(X_train, Y_train)\n",
        "\n",
        "                    test_accuracy = model.score(X_test, Y_test)\n",
        "                    print(f\"Number: {i}, Architecture: {architecture}, Activation: {activation_function}, Epochs: {epoch}, Learning Rate: {learning_rate}, Optimizer: {optimizer}\")\n",
        "                    print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "                    if i % 10 == 0:\n",
        "                      Y_pred = model.predict(X_test)\n",
        "                      matrix = confusion_matrix(Y_test, Y_pred)\n",
        "                      print(\"Confusion Matrix:\")\n",
        "                      print(matrix)\n",
        "                    print()\n",
        "\n",
        "                    i+=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQMl4YvEOvrd"
      },
      "source": [
        "## Wnioski"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9V7e-VN5q3z"
      },
      "source": [
        "W naszych badaniach różnych architektur sieci neuronowych zauważono, że dodawanie dodatkowych warstw i neuronów może potencjalnie poprawić skuteczność klasyfikacji. Jednakże, nie zawsze większa złożoność przekładała się na lepsze wyniki. Przetestowano trzy funkcje aktywacji: relu, logistic i tanh, z czego relu często wydawała się dawać najlepsze wyniki, choć ostatecznie wybór funkcji aktywacji zależy od specyfiki danych. Dodatkowo, badano wpływ liczby epok uczenia (500, 1000, 2000) i współczynnika uczenia (0.1, 0.01, 0.001) na skuteczność klasyfikacji. Wyniki sugerują, że zwiększenie liczby epok może poprawić skuteczność, ale tylko do pewnego punktu, po którym dalsze zwiększanie nie przynosi dodatkowych korzyści lub prowadzi do nadmiernej złożoności modelu. Podobnie, wybór odpowiedniego współczynnika uczenia jest kluczowy, zbyt duży prowadzi do nadmiernej zmienności, a zbyt mały do wolnego uczenia się modelu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17xELNul9Zup"
      },
      "source": [
        "# ZAD 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iCnmToDdjhc"
      },
      "source": [
        "## Kod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3uwcW1ydnF3"
      },
      "source": [
        "Treść:\n",
        "\n",
        "Proszę pobrać zbiór yeast z UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Yeast). Proszę we własnym zakresie dokonać wstępnej analizy i przygotowania tego zbioru (uwaga, wymagana jest zamiana etykiet tekstowych w ostatniej kolumnie na liczbowe - można je zamienić ręcznie albo przy użyciu takich narzędzi jak https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html, należy jednak pamiętać, że nie musi on ułożyć tych etykiet po kolei). Warto zauważyć, że liczności różnych klas wewnątrz zbioru są bardzo nierówne. Proszę spróbować osiągnąć jak najlepsze wyniki i narysować dla nich macierz pomyłek (dla zbioru uczącego i testującego). Czy trafność na poziomie 0.5 dla takiego zbioru jest dobra? Mogą państwo zbadać też czas wykonywania funkcji fit dla różnych konfiguracji sieci."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MRJAni3V9bJt"
      },
      "outputs": [],
      "source": [
        "url1 = \"https://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data\"\n",
        "data = pd.read_csv(url1, header=None, delimiter=r\"\\s+\")\n",
        "\n",
        "X = data.iloc[:, 1:-1]\n",
        "Y = data.iloc[:, -1]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "Y_encoded = label_encoder.fit_transform(Y)\n",
        "\n",
        "train, X_test, Y_train, Y_test = train_test_split(X, Y_encoded, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uflUdaJGnC3P",
        "outputId": "f88b538c-3e90-4379-fda7-10d5b736f1f7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [1437, 1187]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m MLPClassifier(hidden_layer_sizes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m50\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m training_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:752\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    736\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \n\u001b[1;32m    738\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03m        Returns a trained MLP model.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:442\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_layer_sizes must be > 0, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m hidden_layer_sizes\n\u001b[1;32m    437\u001b[0m     )\n\u001b[1;32m    438\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoefs_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m incremental\n\u001b[1;32m    440\u001b[0m )\n\u001b[0;32m--> 442\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# Ensure y is 2D\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1092\u001b[0m, in \u001b[0;36mMLPClassifier._validate_input\u001b[0;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, incremental, reset):\n\u001b[0;32m-> 1092\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1101\u001b[0m         y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1281\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1264\u001b[0m     X,\n\u001b[1;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1277\u001b[0m )\n\u001b[1;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1281\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1437, 1187]"
          ]
        }
      ],
      "source": [
        "model = MLPClassifier(hidden_layer_sizes=(100,50), activation='relu', max_iter=1000, random_state=42)\n",
        "\n",
        "start_time = time.time()\n",
        "model.fit(X_train, Y_train)\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "train_accuracy = model.score(X_train, Y_train)\n",
        "test_accuracy = model.score(X_test, Y_test)\n",
        "\n",
        "print(f\"Train Accuracy: {train_accuracy}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Training Time: {training_time} seconds\")\n",
        "\n",
        "Y_pred_train = model.predict(X_train)\n",
        "cm_train = confusion_matrix(Y_train, Y_pred_train)\n",
        "Y_pred_test = model.predict(X_test)\n",
        "cm_test = confusion_matrix(Y_test, Y_pred_test)\n",
        "\n",
        "print(\"Train confusion matrix: \\n\", cm_train)\n",
        "print(\"Test confusion matrix: \\n\", cm_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-CCYODJdlAF"
      },
      "source": [
        "## Wnioski"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdSStwze6UrZ"
      },
      "source": [
        "Skuteczność klasyfikacji na zbiorze testowym wynosiła około 0.609, a na zbiorze treningowym - około 0.644. Trafność na poziomie 0.5 dla takiego zbioru danych jest niezadowalająca, co sugeruje, że model nie radzi sobie dobrze z zadaniem klasyfikacji w tym przypadku. Analiza macierzy pomyłek pozwala zidentyfikować klasy, które są gorzej klasyfikowane przez model, co może być przydatne w dalszej optymalizacji. Warto zauważyć, że niektóre klasy mają znacznie więcej błędów klasyfikacji niż inne."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "msysGYfP9MiD",
        "iN9Af1iL9TEz",
        "nkKkoZKL9VIK",
        "rGiGkjR89YNU",
        "17xELNul9Zup"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
